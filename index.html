<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Global Cross-Time Attention Fusion for Enhanced Solar Flare Prediction from Multivariate Time Series.">
  <meta name="keywords" content="time series contrastive learning, multivariate time series classification, representation learning, time series analysis, solar flare prediction, deep learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Global Cross-Time Attention Fusion for Enhanced Solar Flare Prediction from Multivariate Time Series</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Global Cross-Time Attention Fusion for Enhanced Solar Flare Prediction from Multivariate Time Series</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://onurvural.github.io">Onur Vural</a>,</span>
            <span class="author-block">Shah Muhammad Hamdi,</span>
            <span class="author-block">Soukaina Filali Boubrahimi</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Utah State University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2511.12955"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2511.12955"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/OnurVural/gctaf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
           Multivariate time series classification is increasingly investigated in space weather research as a means to predict intense solar flare events, which can cause widespread disruptions across modern technological systems. Magnetic field measurements of solar active regions are converted into structured multivariate time series, enabling predictive modeling across segmented observation windows. However, the inherently imbalanced nature of solar flare occurrences, where intense flares are rare compared to minor flare events, presents a significant barrier to effective learning.
          </p>
          <p>
            To address this challenge, we propose a novel Global Cross-Time Attention Fusion (GCTAF) architecture, a transformer-based model to enhance long-range temporal modeling. Unlike traditional self-attention mechanisms that rely solely on local interactions within time series, GCTAF injects a set of learnable cross-attentive global tokens that summarize salient temporal patterns across the entire sequence. These tokens are refined through cross-attention with the input sequence and fused back into the temporal representation, enabling the model to identify globally significant, non-contiguous time points that are critical for flare prediction. This mechanism functions as a dynamic, attention-driven temporal summarizer that augments the model’s capacity to capture discriminative flare-related dynamics. We evaluate our approach on the benchmark solar flare dataset and show that GCTAF effectively detects intense flares and improves predictive performance, demonstrating that refining transformer-based architectures presents a high-potential alternative for performing solar flare prediction tasks.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/h2YrckCUXLI?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

    <!-- Method. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>

        <!-- Framework Section -->
          <h3 class="title is-4">Framework</h3>
          <div class="content has-text-justified">
            <ul>
              <li>GCTAF framework comprises multiple components that combine global and local temporal information from MVTS data by leveraging transformer-based strategies.</li>
              <li>GCTAF attends learnable global tokens to input sequences via cross-attention.</li>
              <li>The fused representation is refined through transformer-based modules, pooled, and classified using an MLP head. </li>
              <li>Transformer Encoder Module: core temporal modeling unit, designed to capture complex temporal dependencies and interactions among solar magnetic field parameters. By employing self-attention and non-linear transformations within a residual framework, it seeks to obtain representations emphasizing salient temporal regions while suppressing irrelevant noise, enabling effective flare prediction.</li>
            </ul>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/GCTAF-ARCH-3.pdf" 
                 alt="Framework Image" 
                 class="framework-image" 
                 style="max-width: 100%; height: auto;">
          </div>
          <p>
            The GCTAF model for solar flare prediction takes input of shape [B, τ, N] and learnable global tokens [1, G, N] shared across batches. 
            The global tokens attend to the input via cross-attention, producing [B, G, N]. 
            The input and global tokens are concatenated to [B, τ+G, N] and processed by transformer encoder blocks. 
            The output is split into local [B, τ, N] and global [B, G, N] tokens. 
            Local tokens are pooled to [B, N], global tokens averaged to [B, N], then concatenated into [B, 2N] and passed through an MLP for final logits.
          </p>
          <!--/ Framework Section -->

        
      </div>
    </div>
    <!--/ Method. -->

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Results Section -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>

        <!-- First Row: Single Figure with Description -->
        <div class="content has-text-centered">
          <img src="./static/images/all_metrics_grouped_barplot.pdf" 
               alt="Results Graph" 
               class="results-image" 
               style="max-width: 100%; height: auto;">
        </div>
        <div class="content has-text-justified">
          <p>
            Bar chart showing flare prediction scores across four metrics. The results demonstrate that refining transformer-based architectures holds potential in MVTS-driven solar flare prediction tasks as GCTAF is able to produce highly competitive results against state-of-the-art approaches in the literature.
          </p>
        </div>

        <!-- Second Row: Figure with Description -->
        <div class="content has-text-centered">
          <img src="./static/images/x9.3flare.pdf" 
               alt="Solar Flare Graph" 
               class="solarflare-image" 
               style="max-width: 100%; height: auto;">
        </div>
        <div class="content has-text-justified">
          <p>
            Intense X9.3-class solar flare captured on September 6, 2017. Credit: NASA/SDO.
          </p>
        </div>

  
      </div>
    </div>
    <!--/ Results Section -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{vural2025globalcrosstimeattentionfusion,
  title={Global Cross-Time Attention Fusion for Enhanced Solar Flare Prediction from Multivariate Time Series},
  author={Vural, Onur and Hamdi, Shah Muhammad and Boubrahimi, Soukaina Filali},
  journal={arXiv preprint arXiv:2511.12955},
  year={2025}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            In this page, the following <a
              href="https://github.com/nerfies/nerfies.github.io">template</a> was used.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
